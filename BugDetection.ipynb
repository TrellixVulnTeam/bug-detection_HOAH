{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa9d885",
   "metadata": {},
   "source": [
    "# CodeNet Dataset\n",
    "\n",
    "In this notebook I intend to make it very easy to visualize all the necessary information about a specific problem. The base dataset I will be using in this notebook is [CodeNet](https://github.com/IBM/Project_CodeNet) which is a large collection of source files and problem descriptions with metadata. The solutions are written in multiple programming languages (55+ according to the paper) and each problem has multiple submissions. Most of the submissions are written in the six most common languages (C++, Python, Java, C, Ruby, C#). As expected most of the solutions are in C++. One interesting aspect of the dataset is that it includes failed submissions, with various status codes such as Compilation Errors, Runtime Errors, Time Limit Exceeded, Memory Limit Exceeded, etc. This will prove useful since we are looking into bug detection in source code files.\n",
    "\n",
    "Make sure you run `source spt.profile` to create the environment for the tokenizer to work. Also you have to compile the tokenizer from CodeNet.\n",
    "\n",
    "# Table of Contents\n",
    "1. [Download CodeNet](#Download-CodeNet)\n",
    "2. [Missing Values](#Missing-Values)\n",
    "3. [Generate Source Code Pairs](#Generate-Source-Code-Pairs)\n",
    "4. [Analyze source code files](#Analyze-source-code-files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ae91f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T21:51:06.927759Z",
     "start_time": "2021-12-11T21:51:06.911836Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "import sys\n",
    "import wget\n",
    "import html\n",
    "import pickle\n",
    "import random\n",
    "import codenet\n",
    "import tarfile\n",
    "import tempfile\n",
    "import itertools\n",
    "import functools\n",
    "import traceback\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import more_itertools as more_itertools\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from difflib import Differ, SequenceMatcher\n",
    "from collections import Counter\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from mydifflib import group_diff_chunks, pdiff, single_change, single_line_changed\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "input_path = \"../input/\"\n",
    "root_path = input_path + \"Project_CodeNet/\"\n",
    "\n",
    "tools_path = \"../Project_CodeNet/tools/\"\n",
    "tokenizer_dir_path = tools_path + \"spt-generator/\"\n",
    "spt_profile = tokenizer_dir_path + \"spt.profile\"\n",
    "tokenizer_path = tokenizer_dir_path + \"scripts/run/tokenize.sh\"\n",
    "\n",
    "data_path = root_path + \"data/\"\n",
    "metadata_path = root_path + \"metadata/\"\n",
    "derived_path = root_path + \"derived/\"\n",
    "descriptions_path = root_path + \"problem_descriptions/\"\n",
    "\n",
    "problem_list_clean_path = input_path + \"problem_list_clean.csv\"\n",
    "generated_pairs_path = input_path + \"generated_pairs.csv\"\n",
    "cleaned_generated_pairs_path = input_path + \"cleaned_generated_pairs.csv\"\n",
    "\n",
    "supported_languages = [\"C\"]\n",
    "\n",
    "\n",
    "def id2desc(problem_id):\n",
    "    return descriptions_path + problem_id + \".html\"\n",
    "\n",
    "\n",
    "def id2inout(problem_id, name=\"input\"):\n",
    "    return derived_path + \"input_output/data/\" + problem_id + \"/\" + name + \".txt\"\n",
    "\n",
    "\n",
    "def id2submission(problem_id, language, submission_id, filename_ext):\n",
    "    return (\n",
    "        data_path\n",
    "        + problem_id\n",
    "        + \"/\"\n",
    "        + language\n",
    "        + \"/\"\n",
    "        + submission_id\n",
    "        + \".\"\n",
    "        + filename_ext\n",
    "    )\n",
    "\n",
    "\n",
    "def read_submission_file(problem_id, language, submission_id, extension):\n",
    "    \"\"\"\n",
    "    Read the source code as a list of lines for a given problem and submission id\n",
    "    the language and extension are also required to complete the path to the file\n",
    "    \"\"\"\n",
    "    with open(id2submission(problem_id, language, submission_id, extension)) as f:\n",
    "        text = f.readlines()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "data_url = \"https://dax-cdn.cdn.appdomain.cloud/dax-project-codenet/1.0.0\"\n",
    "tar_name = \"Project_CodeNet.tar.gz\"\n",
    "tar_path = input_path + tar_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde8520f",
   "metadata": {},
   "source": [
    "## Download CodeNet\n",
    "\n",
    "The next code cell will download the CodeNet dataset from it's original repository (the archive has around 80GB). If you already have the dataset change the input_path variable to point to the root of the dataset, otherwise the notebook will download it in the ../input/ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c2183ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T19:54:28.882872Z",
     "start_time": "2021-12-11T19:54:28.870763Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset root dir found\n"
     ]
    }
   ],
   "source": [
    "codenet.download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f374a417",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4978e3",
   "metadata": {},
   "source": [
    "The dataset also includes a description file for most of the problems. We can see which problems have or don't have a description associated. The description file can be useful to predict what the problem topic is about, graphs, dp, greedy, etc.\n",
    "\n",
    "In the case of missing input files, I think it is also better to just drop the submissions, most of the description files are written in Chinese and we cannot really extract any useful information from them. Since there are so few files with no input we can drop them. By looking in the description files there are like 2 problems with no input from the stdin.\n",
    "\n",
    "To conclude the missing values section, 54/56 of the missing names in the problems list are due to missing description files 1/56 is just a href which links to a 404 web page and the last one is a test problem, the later 2 problems having no submissions anyway. I think it is a fair decision to drop these samples as they are not useful. There will be 130 remaining problems with no input/output samples and 128 of them have description files in Chinese which makes it harder to extract samples, and 2 of them only require printing of values (similar to problem p00000). In this case I also think that it is ok to drop those 2 problems that don't need input alongside the rest of problems that have no input examples extracted, because we don't have to remember that there is one or two problems that can cause some bugs later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f062f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T20:03:27.344767Z",
     "start_time": "2021-12-11T20:03:27.223340Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning ../input/Project_CodeNet/metadata/problem_list.csv\n",
      "We have 3867 problems\n",
      "The distribution of the datasets is\n",
      "AIZU       0.613654\n",
      "AtCoder    0.386346\n",
      "Name: dataset, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>time_limit</th>\n",
       "      <th>memory_limit</th>\n",
       "      <th>rating</th>\n",
       "      <th>tags</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p00001</th>\n",
       "      <td>List of Top 3 Hills</td>\n",
       "      <td>AIZU</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p00002</th>\n",
       "      <td>Digit Number</td>\n",
       "      <td>AIZU</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p00003</th>\n",
       "      <td>Is it a Right Triangle?</td>\n",
       "      <td>AIZU</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p00004</th>\n",
       "      <td>Simultaneous Equation</td>\n",
       "      <td>AIZU</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p00005</th>\n",
       "      <td>GCD and LCM</td>\n",
       "      <td>AIZU</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>131072.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name dataset  time_limit  memory_limit  rating  \\\n",
       "id                                                                          \n",
       "p00001      List of Top 3 Hills    AIZU      1000.0      131072.0     NaN   \n",
       "p00002             Digit Number    AIZU      1000.0      131072.0     NaN   \n",
       "p00003  Is it a Right Triangle?    AIZU      1000.0      131072.0     NaN   \n",
       "p00004    Simultaneous Equation    AIZU      1000.0      131072.0     NaN   \n",
       "p00005              GCD and LCM    AIZU      1000.0      131072.0     NaN   \n",
       "\n",
       "        tags  complexity  \n",
       "id                        \n",
       "p00001   NaN         NaN  \n",
       "p00002   NaN         NaN  \n",
       "p00003   NaN         NaN  \n",
       "p00004   NaN         NaN  \n",
       "p00005   NaN         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "name               0\n",
       "dataset            0\n",
       "time_limit         0\n",
       "memory_limit       0\n",
       "rating          3867\n",
       "tags            3867\n",
       "complexity      3867\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "problem_list_df = pd.read_csv(metadata_path + 'problem_list.csv', index_col=\"id\")\n",
    "problem_list_df = codenet.clean_problem_list(problem_list_df)\n",
    "problem_ids = problem_list_df.index.unique()\n",
    "\n",
    "print(f\"We have {len(problem_list_df)} problems\")\n",
    "print('The distribution of the datasets is')\n",
    "print(problem_list_df['dataset'].value_counts(normalize=True))\n",
    "display(problem_list_df.head())\n",
    "display(problem_list_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a75250",
   "metadata": {},
   "source": [
    "## Generate Source Code Pairs\n",
    "- for each problem:\n",
    "- group solutions by user and select the solutions that are consecutive and of the form (Error, Accepted) with only one instruction (line) changed; heuristic to search a smaller space, since a user might submit a correct solution after a wrong one\n",
    "- get the diff lines the diff operation (add, delete, change) and error type\n",
    "- build a df from this list and save it\n",
    "- sanity check: check that the error types of this df are the same as the types in the problem metadata: Success\n",
    "- done\n",
    "\n",
    "Up until this point we played around with single files and checked the looked at how we can load the source code from the dataset. In this section we will see how we can get the diff between source code files and more specifically the instruction (given by the line in the file) that caused a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7a9d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "generated_pairs_df = codenet.generate_pairs(problem_list_df)\n",
    "generated_pairs_df.to_csv(generated_pairs_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fbe9816",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-11T21:51:11.151172Z",
     "start_time": "2021-12-11T21:51:11.048039Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>changed_id</th>\n",
       "      <th>original_line</th>\n",
       "      <th>diff_op</th>\n",
       "      <th>changed_line</th>\n",
       "      <th>original_status</th>\n",
       "      <th>original_language</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>language</th>\n",
       "      <th>filename_ext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s000088266</td>\n",
       "      <td>s609532420</td>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "      <td>8</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>C</td>\n",
       "      <td>p02392</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s000103279</td>\n",
       "      <td>s107821968</td>\n",
       "      <td>16</td>\n",
       "      <td>c</td>\n",
       "      <td>16</td>\n",
       "      <td>Time Limit Exceeded</td>\n",
       "      <td>C</td>\n",
       "      <td>p00017</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s000134983</td>\n",
       "      <td>s025451182</td>\n",
       "      <td>8</td>\n",
       "      <td>d</td>\n",
       "      <td>7</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>C</td>\n",
       "      <td>p02694</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s000150407</td>\n",
       "      <td>s325747983</td>\n",
       "      <td>18</td>\n",
       "      <td>c</td>\n",
       "      <td>18</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>C</td>\n",
       "      <td>p02258</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s000173494</td>\n",
       "      <td>s918627271</td>\n",
       "      <td>6</td>\n",
       "      <td>c</td>\n",
       "      <td>6</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>C</td>\n",
       "      <td>p02415</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25490</th>\n",
       "      <td>s999918666</td>\n",
       "      <td>s390104290</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>Runtime Error</td>\n",
       "      <td>C</td>\n",
       "      <td>p03134</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25491</th>\n",
       "      <td>s999923152</td>\n",
       "      <td>s735413884</td>\n",
       "      <td>11</td>\n",
       "      <td>c</td>\n",
       "      <td>11</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>C</td>\n",
       "      <td>p00014</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25492</th>\n",
       "      <td>s999951931</td>\n",
       "      <td>s536625431</td>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "      <td>8</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>C</td>\n",
       "      <td>p02990</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25493</th>\n",
       "      <td>s999971044</td>\n",
       "      <td>s120806942</td>\n",
       "      <td>5</td>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>C</td>\n",
       "      <td>p00252</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25494</th>\n",
       "      <td>s999973437</td>\n",
       "      <td>s999081065</td>\n",
       "      <td>24</td>\n",
       "      <td>c</td>\n",
       "      <td>24</td>\n",
       "      <td>Wrong Answer</td>\n",
       "      <td>C</td>\n",
       "      <td>p02921</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25495 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      original_id  changed_id  original_line diff_op  changed_line  \\\n",
       "0      s000088266  s609532420              8       c             8   \n",
       "1      s000103279  s107821968             16       c            16   \n",
       "2      s000134983  s025451182              8       d             7   \n",
       "3      s000150407  s325747983             18       c            18   \n",
       "4      s000173494  s918627271              6       c             6   \n",
       "...           ...         ...            ...     ...           ...   \n",
       "25490  s999918666  s390104290              1       c             1   \n",
       "25491  s999923152  s735413884             11       c            11   \n",
       "25492  s999951931  s536625431              8       c             8   \n",
       "25493  s999971044  s120806942              5       c             5   \n",
       "25494  s999973437  s999081065             24       c            24   \n",
       "\n",
       "           original_status original_language problem_id language filename_ext  \n",
       "0             Wrong Answer                 C     p02392        C            c  \n",
       "1      Time Limit Exceeded                 C     p00017        C            c  \n",
       "2             Wrong Answer                 C     p02694        C            c  \n",
       "3             Wrong Answer                 C     p02258        C            c  \n",
       "4             Wrong Answer                 C     p02415        C            c  \n",
       "...                    ...               ...        ...      ...          ...  \n",
       "25490        Runtime Error                 C     p03134        C            c  \n",
       "25491         Wrong Answer                 C     p00014        C            c  \n",
       "25492         Wrong Answer                 C     p02990        C            c  \n",
       "25493         Wrong Answer                 C     p00252        C            c  \n",
       "25494         Wrong Answer                 C     p02921        C            c  \n",
       "\n",
       "[25495 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25495 entries, 0 to 25494\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   original_id        25495 non-null  object\n",
      " 1   changed_id         25495 non-null  object\n",
      " 2   original_line      25495 non-null  int64 \n",
      " 3   diff_op            25495 non-null  object\n",
      " 4   changed_line       25495 non-null  int64 \n",
      " 5   original_status    25495 non-null  object\n",
      " 6   original_language  25495 non-null  object\n",
      " 7   problem_id         25495 non-null  object\n",
      " 8   language           25495 non-null  object\n",
      " 9   filename_ext       25495 non-null  object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 1.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "C    25495\n",
       "Name: language, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Wrong Answer              17990\n",
       "Runtime Error              3614\n",
       "WA: Presentation Error     3266\n",
       "Time Limit Exceeded         587\n",
       "Memory Limit Exceeded        28\n",
       "Output Limit Exceeded        10\n",
       "Name: original_status, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_pairs_df = pd.read_csv(generated_pairs_path)\n",
    "\n",
    "display(generated_pairs_df)\n",
    "display(generated_pairs_df.info())\n",
    "display(generated_pairs_df.language.value_counts())\n",
    "display(generated_pairs_df.original_status.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd86a189",
   "metadata": {},
   "source": [
    "So we can see that after running this preprocessing function on all the problems we are left with 100,000 samples of pairs of source code files of the form (error, successful) for all the languages in the dataset. We will have to analyze the source code files that we obtained and make sure they are well suited for being tokenized and used in a machine learning algorithm. Now the error messages that are provided in this dataset don't look that useful, so in the next steps I will attempt to improve the error messages by running the source code on sample inputs or using compilers, code check tools etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d27f2",
   "metadata": {},
   "source": [
    "## Clean Source Code Pairs\n",
    "- for each problem in the :\n",
    "- drop the submissions with compile error status, we are only interested in runtime errors\n",
    "- group solutions by user and select the solutions that are consecutive and of the form (Error, Accepted) with only one instruction changed; heuristic to search a smaller space, since a user might submit a correct solution after a wrong one\n",
    "- use the AST Tokenizer for C, C++, Java and Python to generate the tokens for each pair of submission files\n",
    "- use an edit distance algorithm to detect the diff between the two submissions and save the information\n",
    "- build a df from this list and save it\n",
    "\n",
    "Up until this point we played around with single files and checked the looked at how we can load the source code from the dataset. In this section we will see how we can get the diff between source code files and more specifically the instruction (given by the line, token, in the file) that caused a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a363fdf",
   "metadata": {},
   "source": [
    "One interesting aspect here is how many users sent more than one submission and also have submissions of the form (failed, accepted) and have only one instruction changed so that we can understand what change made their code work. To do this we need to first split each source file into tokens and then implement a function that computes the edit distance and the get_opcodes of the two tokens lists. Luckily the CodeNet repository contains a tool written in Java that can tokenize correct source code (only C, C++, Java and Python), meaning that we have to drop compilation errors, which are not that interesting for this subject anyway. Then to compute the op_codes for the edit distance we can use the difflib SequenceMatcher class from Python.\n",
    "\n",
    "Some notes:\n",
    "- The C Tokenizer needs to delete the include statements, so they might be shifted in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb410b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "generated_pairs_df = clean_genereated_pairs(generated_pairs_df)\n",
    "generated_pairs_df.to_csv(cleaned_generated_pairs_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f7739a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "generated_pairs_df = pd.read_csv(cleaned_generated_pairs_path)\n",
    "\n",
    "display(generated_pairs_df)\n",
    "display(generated_pairs_df.info())\n",
    "display(generated_pairs_df.language.value_counts())\n",
    "display(generated_pairs_df.original_status.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
